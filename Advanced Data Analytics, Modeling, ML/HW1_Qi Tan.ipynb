{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JvbRNAxUrLe"
      },
      "source": [
        "# QM 701: Advanced Data Analytics and Applications\n",
        "# Homework 1\n",
        "\n",
        "---\n",
        "## Objective\n",
        "The goal of this homework is get a first look at natrual language processing via sentiment analysis. In this homework, you will delve into the fundamental principles of sentiment analysis, explore various techniques, and gain hands-on experience by implementing sentiment analysis on real-world text data.\n",
        "\n",
        "## Tasks\n",
        "This homework includes the following 6 questions.\n",
        " - **Q1**: Concepts of Sentiment Analysis in Business. (20 points)\n",
        " - **Q2**: Loading and Viewing Data (20 points)\n",
        " - **Q3**: Naive Bayes for Sample Tweets (20 points)\n",
        " - **Q4**: Pre-Built Sentiment Analyzers (20 points)\n",
        " - **Q5**: Lexicon Matching (20 points)\n",
        " - **Bonus** Manipulating Scores of Sentiment Analyzers (10 points)\n",
        "\n",
        "Hint: As you work through the questions, you may find the notebooks posted under Class 1 (the in-class notebook and the two pre-class notebooks) helpful.\n",
        "\n",
        "\n",
        "\n",
        "## Format for each question.\n",
        "For each question, you may have to answer by text, by coding, or both. For example, consider the following question:\n",
        "\n",
        "# Q0: a) Compute 3+5 using Python. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBNDXfyDhkfJ",
        "outputId": "51e65f6b-81cb-47d0-8688-6011fd8a339d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n"
          ]
        }
      ],
      "source": [
        "# Your code for the question above.\n",
        "print(3+5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## b) Describe in words another method for computing 3+5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os7dsexahqSa"
      },
      "source": [
        "Your (text) answer to the question above: \n",
        "\n",
        "Example answer\n",
        "\n",
        "I can compute 3+5 by counting my fingers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDEu9jkr-AvK"
      },
      "source": [
        "# Q1: Concepts of Sentiment Analysis in Business\n",
        "\n",
        "## a) Please describe one business case (existing or proposed) where using Sentiment Analysis could create business value in your industry, field, role, or organization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9vpPd7l-ydR"
      },
      "source": [
        "Your answer to the question above:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6biJHfH_HtJ"
      },
      "source": [
        "## b) How would it create value? And how would you measure or showcase that value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX6xbpxP_Fvp"
      },
      "source": [
        "Your answer to the question above:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emv1lLpK-zuS"
      },
      "source": [
        "## c) What are some of the challenges (list up to three) for interpreting sentiment? Can a sentence have both positive or negative sentiment?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhFiOlHIAt3l"
      },
      "source": [
        "Your answer to the question above:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSkdtlT0V2gy"
      },
      "source": [
        "# Q2: Loading and Viewing Data\n",
        "Hint: Review the codes in 'PreClass1_Twitter_Data.ipynb' file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6lnhSygAUjrW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import itertools\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from textblob import TextBlob\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhCY6Q5ZU5iY",
        "outputId": "0f22388f-3003-4bcd-f9f7-2ada93c5c8bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Loading the twitter_samples data set. The Tweets (or 'status updates') were collected from the Twitter Streaming APIs (see [API Documentation](https://dev.twitter.com/overview/documentation), [Streaming Overview](https://dev.twitter.com/streaming/overview)). Each file consists of line-separated JSON-formatted tweets, i.e. one Tweet per line. For a detailed description of the JSON fields in a Tweet, see [Tweets: Field Guide](https://dev.twitter.com/overview/api/tweets).\n",
        "\n",
        "# The tweets are associated with politics in UK from the public stream of the Streaming API using the `statuses / filter` endpoint.\n",
        "# The value of `track` was set to the following keywords: \"david cameron, miliband, milliband, sturgeon, clegg, farage, tory, tories, ukip, snp, libdem\"\n",
        "\n",
        "\n",
        "nltk.download('twitter_samples')\n",
        "\n",
        "sample_df = pd.read_json('/root/nltk_data/corpora/twitter_samples/tweets.20150430-223406.json', lines=True)\n",
        "\n",
        "# Loading the positive and negative data sets used in class. These data sets are not associated with the UK politics.\n",
        "positive_df = pd.read_json('/root/nltk_data/corpora/twitter_samples/positive_tweets.json',lines=True)\n",
        "negative_df = pd.read_json('/root/nltk_data/corpora/twitter_samples/negative_tweets.json',lines=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTw_KNBorgCJ"
      },
      "source": [
        "\n",
        "Answer the following questions using 'sample_df' (hint: you may refer to 'PreClass1_Twitter_Data' notebook to answer this question):\n",
        "\n",
        "### a) What is the first two tokens (ignoring the symbols and special characters) in the 11th tweet?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "myN3VmE4qOSL"
      },
      "outputs": [],
      "source": [
        "#Your code for the question above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VxI-9M2uinQ"
      },
      "source": [
        "Please enter your answer to the question above here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnWLxrKP877s"
      },
      "source": [
        "### b) What is the average text length (measured in number of characters) of the tweets?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code for the question above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLbmnZFeqQDg"
      },
      "source": [
        "Please enter your answer to the question above here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZOjSZSDur7A"
      },
      "source": [
        "### c) Text Visualization.\n",
        "### Combine all tweets in sample_df into a single string and then create a word cloud using it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code for the question above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HrRAr5SUp4H"
      },
      "source": [
        "# Q3: Naive Bayes for Sample Tweets\n",
        "\n",
        "We will build a Naive Bayes model using the same code used in Class 1, using the positive and negative tweets. Then, we apply the Naive Bayes model to the sample tweets dataset. Run the code below then answer the following questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "B5cg9v3UByap",
        "outputId": "abff79e6-8d49-4215-ffaf-81dc6b622d70"
      },
      "outputs": [],
      "source": [
        "# Code for Training the Naive Bayes Model in Class 1\n",
        "\n",
        "#Label the datasets of positive and negative tweets and  concatenates both datasets into a single DataFrame.\n",
        "positive_df['y'] = 1\n",
        "negative_df['y'] = 0\n",
        "labled_df = pd.concat([positive_df, negative_df])\n",
        "\n",
        "#Training a Naive Bayes model using the positve and negative tweets.\n",
        "X = labled_df['text']\n",
        "y = labled_df['y']\n",
        "vectorizer = CountVectorizer()\n",
        "X_v = vectorizer.fit_transform(X)\n",
        "model_nb = MultinomialNB()\n",
        "model_nb.fit(X_v, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8vGd4u1DBkIz"
      },
      "outputs": [],
      "source": [
        "# Tokenize the sample tweets\n",
        "X_sample = sample_df['text']\n",
        "X_sample_v = vectorizer.transform(X_sample)\n",
        "\n",
        "# Compute probabilities using the NB model, on the sample tweets - this returns (gives us) a array (20000x2) for 20,000 tweets for my two classes (negative and positive)\n",
        "y_sample_pred_probs = model_nb.predict_proba(X_sample_v)\n",
        "\n",
        "# To make it easier to manipulate the data, we are going to convert that array (list) to a DataFrame which makes it easier to work with.\n",
        "probs_df = pd.DataFrame(y_sample_pred_probs)\n",
        "\n",
        "#Attach/copy the predicted probability for each of the tweet being positive\n",
        "sample_df['NBPosScore'] = probs_df[1]\n",
        "\n",
        "#Drop all columns except the tweets and NBPosScore\n",
        "sample_df = sample_df[['text','NBPosScore']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9S-jy3SiZiP"
      },
      "source": [
        "### a) Find and display the top 5 most positive tweets and top 5 most negative tweets for Naive-Bayes. Do you agree with the classification? Why or why not?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "wbr7_gG_nlkR"
      },
      "outputs": [],
      "source": [
        "# Your code for the question above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD9kzGQbi3Qd"
      },
      "source": [
        "Please enter your answer (on whether you agree with the classfication or not and why) here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TflUVwOoxRz"
      },
      "source": [
        "### b) Suppose that we want to classify all the tweets in sample_df with positive or negative sentiments using our Naive Bayes model. How can we measure the accuracy of the classification?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLSlEmbIphRZ"
      },
      "source": [
        "Please enter your answer here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYsLO7cvoMLt"
      },
      "source": [
        "### c) Please list at least two items that we can do to improve the accuracy of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoOwUodAoeVb"
      },
      "source": [
        "Please enter your answer to the question above here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfWoOeR1tOBt"
      },
      "source": [
        "### d) As we learned from the class, CountVectorizer vectorizes each tweet into a vector corresponding to the count of different tokens. The code below uses the 'get_feature_names_out()' function from CountVectorizer) to print out a lsit of all the tokens. Do you think removing some of the tokens would improve the accuracy of our Naive Bayes model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "print(vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_hkjbVXu8O9"
      },
      "source": [
        "Please enter your answer to the question above here:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKc4fkg8KnrI"
      },
      "source": [
        "# Q4: Pre-Built Sentiment Analyzers\n",
        "\n",
        "As an alternative to Naïve-Bayes, we can also use pre-built sentiment analyzer such as TextBlob and SentimentIntensityAnalyzer from NLTK to perform an analysis on the sample tweet dataframe. Compare the results of Naïve-Bayes with TextBlob, and SentimentIntensityAnalyzer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MF3Jg-EvWHK",
        "outputId": "dfceed2e-a5bc-4e56-b340-f919427c5a37"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "# SentimentIntensityAnalyzer is a VADER sentiment analysis tool from nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# TextBlob provides a simple API for common NLP tasks\n",
        "from textblob import TextBlob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s1siwTOvW7x"
      },
      "source": [
        "### a) Look at the top 5 most positive tweets for TextBlob and SentimentIntensityAnalyzer (SIA). Based on the 5 most positive tweets, how do TextBlob and SIA compare with Naive Bayes? (Note: for TextBlob, there should be over 100 tweets with a sentiment score of 1.0, looking at any five of them is fine)\n",
        "\n",
        "Hint: you need to first create \"TextBlob\" to display the scores from TextBlob, and a \"sia_positive\" and \"sia_negative\" columns "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "vme7MDH_v-eX"
      },
      "outputs": [],
      "source": [
        "# Create a 'TBlobTextBlob' column in sample_df to store TextBlob's polarity score for each tweet.\n",
        "# Replace this line with code\n",
        "\n",
        "\n",
        "# Create a 'sia_positive' column in sample_df to store SIA's positive score for each tweet.\n",
        "# Replace this line with code\n",
        "\n",
        "\n",
        "\n",
        "# Create a 'sia_negative' column in sample_df to store SIA's positive score for each tweet.\n",
        "# Replace this line with code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Hint: use pandas.DataFrame.nlargest() function.\n",
        "\n",
        "print(\"Top 5 most positive tweets by TextBlob:\")\n",
        "#Replace this line with code to print out the top 5 most positive tweets for TextBlob\n",
        "\n",
        "print(\"Top 5 most negative tweets by TextBlob:\")\n",
        "#Replace this line with code to print out the top 5 most negative tweets for TextBlob\n",
        "\n",
        "print(\"Top 5 most positive tweets by SentimentIntensityAnalyzer:\")\n",
        "#Replace this line with code to print out the top 5 most positive tweets for SIA\n",
        "\n",
        "print(\"Top 5 most negative tweets by SentimentIntensityAnalyzer:\")\n",
        "#Replace this line with code to print out the top 5 most negative tweets for SIA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjjhDoe1v_Ai"
      },
      "source": [
        "Please enter your answer to the question above here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghTuEsrCv_1n"
      },
      "source": [
        "### b) Provide a potential scenario where our Naive Bayes approach can outperform the pre-built sentiment analyzers. Note: you do not need a) for this question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qad_WSfwZb6"
      },
      "source": [
        "Please enter your answer to the question above here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daeIBDLdePr1"
      },
      "source": [
        "# Q5: Lexicon Matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "NISPNjT8c590"
      },
      "outputs": [],
      "source": [
        "#positive_lexicons\n",
        "positive_lexicons = [ ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
        "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
        "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
        "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
        "    '<3']\n",
        "\n",
        "negative_lexicons = [':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
        "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
        "    ':c', ':{', '>:\\\\', ';(']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHW_qvIewk1g"
      },
      "source": [
        "### a) How many tweets in sample_df contain positive lexicons? What about negative lexicons?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "PAej0dg-wdCO"
      },
      "outputs": [],
      "source": [
        "# Your code for the question above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Please enter your answer to the question above here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEPzoZ2mw9Bu"
      },
      "source": [
        "### b) Do you prefer Naive Bayes or the Lexicon Matching in classifying the tweets in sample_df? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vln9e-LoYsEK"
      },
      "source": [
        "Please enter your answer to the question above here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yBmN9OrxnfX"
      },
      "source": [
        "# Bonus Question: Manipulating Scores of Sentiment Analyzers\n",
        "\n",
        "Next, let us evaluate the performance of the sentiment analyzer you built using the Naive Bayes approach against other well-established sentiment analyzers.\n",
        "\n",
        "### a) Take the sentence, \"The thai food in this town tastes terrible\", and compute and print the sentiment scores using i) SentimentIntensityAnalyzer (SIA), ii) TextBlob, and iii) Naive Bayes model (the model 'model_nb' we built earlier).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code for the question above.\n",
        "\n",
        "#Hint: To use 'model_nb' to assess the sentiment, you may need vectorizer.transform to tokenize \"The thai food in this town tastes terrible\" first. To do so, use the command vectorizer.transform([\"The thai food in this town tastes terrible\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uH_q8KK0kKS"
      },
      "source": [
        "### b) Manipulating Sentiment Analysis Outputs\n",
        "\n",
        "Create a sentence with a similar meaning to the given sentence \"The thai food in this town tastes terrible\", but achieves:\n",
        "\n",
        "(i) A positive score of at least 0.5 using your Naive Bayes sentiment analyzer.\n",
        "\n",
        "(ii) A polarity score of at least 0.5 when analyzed using Textblob\n",
        "\n",
        "(iii) A positive score that is larger than the negative score using SIA\n",
        "\n",
        "\n",
        "Print the sentiment scores for the new sentence from all of the analyzers. (Hint: Think about how sentiment analyzers may perceive certain words.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code for the question above."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
