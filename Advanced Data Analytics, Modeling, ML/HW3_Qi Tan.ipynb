{"cells":[{"cell_type":"markdown","metadata":{"id":"Lk-AwWkSx5V_"},"source":["# QM 701: Advanced Data Analytics and Applications\n","# Homework 3\n","---\n","## Objective\n","This homework is designed to enhance your understanding of word embeddings using Word2Vec and FastText models. You will work with a dataset of movie reviews, import, preprocess, and analyze the text data. The primary objectives include training Word2Vec and FastText models, exploring word similarity, and comparing models trained on domain-specific data versus pre-trained models on some larger corpora.\n","\n","\n","## Tasks\n","In this homework, you will implement **language models** for **learning word embeddings**. The homework includes the following 5 questions:\n","\n","* **Q1**: Text Pre-Processing. You will start by importing and preprocessing a dataset of movie reviews. (15 points)\n","* **Q2**: Model Training. You need to train **Word2Vec** and **FastText** models under different settings on the processed dataset. (20 points)\n","* **Q3**: Model Evaluation. Using these trained models, you are required to find the synonyms of the given tokens. (20 points)\n","* **Q4**: Model Comparison. You will compare your models with some other models that are pre-trained on large and more datasets. (20 points)\n","* **Q5**: Non-Coding Questions. You can check your understandings about language models and word embeddings by answering these questions. (25 points)\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"0D6WIXJ5V55Q","executionInfo":{"status":"ok","timestamp":1719799288871,"user_tz":240,"elapsed":3774,"user":{"displayName":"Qi Tan","userId":"00069661742172985235"}}},"outputs":[],"source":["# import packages\n","# feel free to import other libraries here\n","import pprint as pp\n","import numpy as np\n","import pandas as pd\n","import gensim"]},{"cell_type":"markdown","metadata":{"id":"0alcaISo6CaY"},"source":["## File and Data setup\n","\n","For this assignment, we will use the movie review dataset, which is originally from the paper *Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts (Pang & Lee, ACL 2004)*. This dataset includes 2k reviews on movies **before 2002**. You may check the detailed description on the dataset from their [paper](https://aclanthology.org/P04-1035/) and [website](https://www.cs.cornell.edu/people/pabo/movie-review-data/).\n","\n","This dataset is supported and distributed by NLTK, which enables us to download it easily."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"LxJk-LtydQzl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719799293111,"user_tz":240,"elapsed":4242,"user":{"displayName":"Qi Tan","userId":"00069661742172985235"}},"outputId":"18dc3cf9-4bcc-4459-d90c-b9fff8016bd3"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/movie_reviews.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]}],"source":["# download required corpora\n","import nltk\n","nltk.download([\"movie_reviews\", \"wordnet\", \"averaged_perceptron_tagger\"])\n","from nltk.corpus import movie_reviews"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"3-4YAGwmtypF","executionInfo":{"status":"ok","timestamp":1719799300326,"user_tz":240,"elapsed":5432,"user":{"displayName":"Qi Tan","userId":"00069661742172985235"}}},"outputs":[],"source":["# transform the dataset into a pandas Series object,\n","# where each element of the Series is the full text of a movie review,\n","# with words separated by spaces\n","doc = [\" \".join(movie_reviews.words(file_id)) for file_id in movie_reviews.fileids()]\n","text_series = pd.Series(doc)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"PCL366AN1qBB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719799307080,"user_tz":240,"elapsed":149,"user":{"displayName":"Qi Tan","userId":"00069661742172985235"}},"outputId":"e9c28b18-1669-44b8-f61c-4d7d91755cf3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["count     2000.0000\n","mean      3904.2600\n","std       1718.6621\n","min         91.0000\n","25%       2745.5000\n","50%       3640.5000\n","75%       4730.5000\n","max      15097.0000\n","dtype: float64"]},"metadata":{},"execution_count":4}],"source":["# inspect the Series using the describe() method\n","text_series.str.len().describe()"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"5Gh-7TxA2iZ1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719799319831,"user_tz":240,"elapsed":167,"user":{"displayName":"Qi Tan","userId":"00069661742172985235"}},"outputId":"554255ce-2497-4f02-ce00-83e985fac9c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["('james l . brooks , one of the developers of the simpsons and director of broadcast news , '\n"," 'returns to the big screen with this entertaining , if slightly flawed comedy . nicholson plays '\n"," \"melvin udall , probably the most horrible person ever on the screen . he ' s racist , homophobic \"\n"," ', and never has a good word to say to anyone . so , nobody talks to him , except waitress carol '\n"," 'conelly ( t . v sitcom star hunt , who was last seen in twister , 1996 ) . naturally , udall , '\n"," 'conelly and gay neighbor simon bishop ( kinnear ) who nicholson hates , all hit it off in the '\n"," 'end . like good will hunting ( 1997 ) and titanic ( 1997 ) , even though the outcome is '\n"," 'completely obvious , as good as it gets is an enjoyable , funny and warm comedy . nicholson is '\n"," 'hilarious as melvin , churning out insults with superb relish . only nicholson could get away '\n"," 'with the lines that melvin delivers . hunt is also good as waitress carol , and easily rises to '\n"," \"the challenge of nicholson . there ' s also ( thankfully ) a bit of chemistry between them . \"\n"," \"kinnear , as the gay neighbor , seems to have a slightly underwritten role , he ' s more of a \"\n"," 'plot convience than a character . although his performance is good , his character just seems to '\n"," \"exist to help melvin and carol come together . in fact , the scene stealer is simon ' s dog , \"\n"," 'who is funnier than nicholson . but then again , pets are always cute on screen . providing '\n"," 'solid support is cuba gooding , jnr ( jerry maguire , 1996 ) and yeardly smith ( who is the '\n"," \"voice of lisa simpsons in the simpsons ) although gooding isn ' t as good as is character in \"\n"," 'maguire , he is still fun . he overacts a little , but not so much as to be annoying . smith is '\n"," 'also good , although she has a fairly small role . even director lawrence kasdan ( body heat , '\n"," '1981 ) makes an appearance as a doctor . but this is primarily nicholsons film , and every scene '\n"," \"he ' s in , he ' s steals it . he ' s character is so hateful , though , it ' s amazing that \"\n"," 'anyone talks to him at a')\n"]}],"source":["# Display a review\n","pp.pprint(text_series[1100][0:2000], width=100, compact=True)"]},{"cell_type":"markdown","metadata":{"id":"ZJt0qRcS681u"},"source":["## Q1. Text Pre-Processing\n","\n","In this section, we will first preprocess the dataset and format it for the model training.\n","\n","We already provide the code for main part of the preprocessing for you. Your task is to define your `CUSTOM_FILTERS` of gensim functions to remove punctuations, digits, and stopwords.\n","\n","Hint: You may check our posted `Class3.ipynb` notebook about preprocessing for some help. You can also find the official documentatios of `gensim` about their preprocessing functions [here](https://radimrehurek.com/gensim/parsing/preprocessing.html#gensim.parsing.preprocessing.preprocess_string)."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"prShTCoI2OCs","executionInfo":{"status":"ok","timestamp":1719799438446,"user_tz":240,"elapsed":139,"user":{"displayName":"Qi Tan","userId":"00069661742172985235"}}},"outputs":[],"source":["import gensim.parsing.preprocessing as preprocess\n","from nltk.stem import WordNetLemmatizer\n","# Your code for Q1: define your CUSTOM_FILTERS of gensim functions to apply preprocessing steps.\n","CUSTOM_FILTERS =  [preprocess.strip_punctuation, preprocess.strip_numeric, preprocess.remove_stopwords]"]},{"cell_type":"markdown","metadata":{"id":"pfE3z3YRJkdC"},"source":["With your `CUSTOME_FILTERS`, you can run the following codes for preprocessing without any edits needed.\n","\n","It may take up to 2mins to finish the preprocessing (mostly due to the lemmatization)."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"ynhJbWnGyajE","executionInfo":{"status":"ok","timestamp":1719799487964,"user_tz":240,"elapsed":47874,"user":{"displayName":"Qi Tan","userId":"00069661742172985235"}}},"outputs":[],"source":["def lemmatize_text(token_list, wnl):\n","  \"\"\"\n","  This function tags the pos of the input tokens,\n","  and lemmatize the tokens.\n","  \"\"\"\n","  # POS tag each word\n","  for word, tag in nltk.pos_tag(token_list):\n","    # Mapping the pos tags to the types supported by wnl\n","    if tag.startswith(\"NN\"):\n","      yield wnl.lemmatize(word, pos='n')\n","    elif tag.startswith('VB'):\n","      yield wnl.lemmatize(word, pos='v')\n","    elif tag.startswith('JJ'):\n","      yield wnl.lemmatize(word, pos='a')\n","    elif tag.startswith('RB'):\n","      yield wnl.lemmatize(word, pos='r')\n","    else:\n","      yield wnl.lemmatize(word)\n","\n","# Remove punctuations, digits, and stopwords with your defined CUSTOM_FILTERS\n","processed_text = text_series.apply(lambda x: preprocess.preprocess_string(x, CUSTOM_FILTERS))\n","\n","# Lemmatize the tokens\n","wnl = nltk.WordNetLemmatizer()\n","processed_text = processed_text.apply(lambda x: \" \".join(lemmatize_text(x, wnl)))\n","\n","# Lower the letters and return a token list of each review\n","processed_text = processed_text.apply(lambda x: gensim.utils.simple_preprocess(x, deacc=False))"]},{"cell_type":"markdown","metadata":{"id":"USdt1UY68TpB"},"source":["## Q2. Model Training\n","\n","After finishing the preprocessing, let's turn to some famous language models for word embeddings. You are required to train two **Word2Vec** models and two **FastText** models, using continuous **bag of words (CBOW)** and **skip-grams (SG)**.\n","\n","In total, you should have the following four models. Please **name** the models using the following names:\n","\n","*   w2v_cbow: Word2Vec + CBOW\n","*   w2v_sg: Word2Vec + SG\n","*   ft_cbow: FastText + CBOW\n","*   ft_sg: FastText + SG\n","\n","Please ensure to name your models exactly as above.\n","\n","You may consider training these models using `gensim`. In that case, training each of the models takes around 1-2 minutes. You may check the `gensim`'s documentation on [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html) and [FastText](https://radimrehurek.com/gensim/models/fasttext.html). You are free to try different hyperparameters.\n","\n","Note: Skip-Gram tends to work well with a small amount of data and is found to represent rare words well. On the other hand, CBOW is faster and has better representations for more frequent words.\n","\n","Hint 1: If you choose to use `gensim`, you may first import these models like this\n","\n","``` python\n","from gensim.models import Word2Vec, FastText\n","```\n","Hint 2: Like to Class 3 notebbok, you should start your `gensim` model training like this\n","```python\n","w2v_cbow = Word2Vec(...)\n","```"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"TA78fJdL3I0N","executionInfo":{"status":"ok","timestamp":1719800080311,"user_tz":240,"elapsed":210418,"user":{"displayName":"Qi Tan","userId":"00069661742172985235"}}},"outputs":[],"source":["# Your code for Q2.\n","from gensim.models import Word2Vec, FastText\n","\n","\n","w2v_cbow = Word2Vec(sentences=processed_text, vector_size=100, window=5, min_count=5, epochs=10, workers=4, sg=0)\n","w2v_sg = Word2Vec(sentences=processed_text, vector_size=100, window=5, min_count=5, epochs=10, workers=4, sg=1)\n","ft_cbow = FastText(sentences=processed_text, vector_size=100, window=5, min_count=5, epochs=10, workers=4, sg=0)\n","ft_sg = FastText(sentences=processed_text, vector_size=100, window=5, min_count=5, epochs=10, workers=4, sg=1)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"__Vjo4JT5BYQ"},"source":["## Q3. Model Evaluation: Synonyms\n","With the trained models, we can find the most similar words (i.e., synonyms) of given tokens based on their word embeddings."]},{"cell_type":"markdown","metadata":{"id":"XT1EaTKVBlr9"},"source":["### a) Single Input Token\n","For 3a), we will examine the top-10 most similar words for several tokens. After each displayed top-10 most similar words, be sure to discuss any thing you find interesting."]},{"cell_type":"markdown","metadata":{"id":"kKQ0sNZNXfYv"},"source":["The following code generates the top-10 most similar words for \"**disney**\" using w2v_sg (Word2vec + SG).\n","\n","If you named and trained your model according to the instruction of Q2, you can run the following code witout any edits needed."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"0T8qoyeGrKRt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719800080311,"user_tz":240,"elapsed":3,"user":{"displayName":"Qi Tan","userId":"00069661742172985235"}},"outputId":"a8b034c9-561a-49de-e6ee-77baf5144add"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('animation', 0.7560753226280212),\n"," ('animate', 0.7494263052940369),\n"," ('dreamworks', 0.7273356318473816),\n"," ('animated', 0.7238619923591614),\n"," ('pocahontas', 0.722666323184967),\n"," ('mermaid', 0.7204435467720032),\n"," ('hercules', 0.6872342824935913),\n"," ('hunchback', 0.6869755983352661),\n"," ('walt', 0.6835805177688599),\n"," ('dame', 0.6810756325721741)]"]},"metadata":{},"execution_count":11}],"source":["# top-10 most similar words for \"disney\" using w2v_sg\n","w2v_sg.wv.most_similar(positive=\"disney\")"]},{"cell_type":"markdown","metadata":{"id":"sc3OviI5YQfj"},"source":["The following codes generate the top-10 most similar words for \"**oscar**\" using ft_sg (FastText + SG).\n","\n","If you name and train your model correctly, you can run the following code witout any edits needed."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"OEtLomBY7eBn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719800092762,"user_tz":240,"elapsed":153,"user":{"displayName":"Qi Tan","userId":"00069661742172985235"}},"outputId":"5da0c207-3835-46bb-ebac-7faad9767536"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('nominee', 0.8424609899520874),\n"," ('nomi', 0.8273019194602966),\n"," ('nominate', 0.8212134838104248),\n"," ('nominated', 0.8141596913337708),\n"," ('nomination', 0.8136633038520813),\n"," ('academy', 0.7813323140144348),\n"," ('award', 0.7514181733131409),\n"," ('accolade', 0.7081405520439148),\n"," ('winner', 0.6830302476882935),\n"," ('globe', 0.677161693572998)]"]},"metadata":{},"execution_count":12}],"source":["# top-10 most similar words for \"oscar\" using ft_sg\n","ft_sg.wv.most_similar(positive=\"oscar\")"]},{"cell_type":"markdown","metadata":{"id":"7d9vZVuAeIcK"},"source":["The following codes generate the top-10 most similar words for \"**actress**\" using ft_cbow (FastText + CBOW).\n","\n","If you name and train your model correctly, you can run the following code witout any edits needed."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Z2pgfPBBdLIH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719800100787,"user_tz":240,"elapsed":179,"user":{"displayName":"Qi Tan","userId":"00069661742172985235"}},"outputId":"cb7ff324-02a8-4f7c-94ca-f8d9c1accae7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('actresses', 0.9699483513832092),\n"," ('roles', 0.8727955222129822),\n"," ('keanu', 0.8705829977989197),\n"," ('role', 0.8694130778312683),\n"," ('support', 0.8523364663124084),\n"," ('actor', 0.8521780371665955),\n"," ('performer', 0.8507847785949707),\n"," ('charisma', 0.8448072075843811),\n"," ('perky', 0.8443838953971863),\n"," ('nicole', 0.8372035026550293)]"]},"metadata":{},"execution_count":13}],"source":["# top-10 most similar words for \"actress\" using ft_cbow\n","ft_cbow.wv.most_similar(positive=\"actress\")"]},{"cell_type":"markdown","metadata":{"id":"vn-K4u24Blr-"},"source":["**Answer:** w2v_sg: predict its surrounding context words. <br>\n","ft_sg: Similar to w2v_sg but includes subwords, like 'nominee','nomi','nominate','nominated','nomination' <br>\n","ft_cbow: it predicts a target word from the average of its context subwords. from actress, I believe it derived act, where actor, roles, person names come from."]},{"cell_type":"markdown","metadata":{"id":"gZQVhg04YweQ"},"source":["### b) Multiple Input Tokens\n","Our models can also find the similar words for multiple input tokens. The following code generates the top-10 most similar words for two tokens: \"**kung**\" and \"**fu**\" using w2v_cbow. Examine the output and describe any interesting findings.\n","\n","If you name and train your model correctly, you can run the following code witout any edits needed."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"4wBhUe0RYvyx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719801103491,"user_tz":240,"elapsed":148,"user":{"displayName":"Qi Tan","userId":"00069661742172985235"}},"outputId":"10563a60-e00f-4026-cd2d-ecb526040819"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('choreograph', 0.8920067548751831),\n"," ('jet', 0.8469336032867432),\n"," ('kong', 0.8339348435401917),\n"," ('hong', 0.8251234889030457),\n"," ('slo', 0.8224210143089294),\n"," ('spectacular', 0.8176441788673401),\n"," ('heavy', 0.8067103624343872),\n"," ('lam', 0.8032325506210327),\n"," ('jaw', 0.8006710410118103),\n"," ('choreography', 0.7998129725456238)]"]},"metadata":{},"execution_count":14}],"source":["# top-10 most similar words for \"disney\" using w2v_sg\n","w2v_cbow.wv.most_similar(positive=[\"kung\", \"fu\"])"]},{"cell_type":"markdown","metadata":{"id":"1bHfiudKBlr-"},"source":["**Answer: ** w2v_cbow: It is the opposite of w2v_sg. CBOW predicts a target word based on its context. For example, given context words like \"saving\", \"account\", it might predict \"bank\". <br>\n","In our case, it finds Kung Fu, and find its contectual words like \"choreograph\", \"Jet Li\", \"spectacular\", \"hong kong\", etc."]},{"cell_type":"markdown","metadata":{"id":"9dqV3mGzfr_i"},"source":["### c) Your Own Token\n","It's your turn to play with the models! Try to find one token such that at least one of our models to generate top-10 similar words for one or multiple tokens. Then, explain your finding (ie., why the top-10 words make sense or why they do not make sense).\n","\n","Hint 1: The dataset only includes reviews on movies before 2002. Our models are not familiar with any movies released after that.\n","\n","Hint 2: For the same input token, our models may have very different performance. So try all of these four models and find the best one."]},{"cell_type":"code","execution_count":19,"metadata":{"id":"ntEyUv6cq9Fp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719803068152,"user_tz":240,"elapsed":141,"user":{"displayName":"Qi Tan","userId":"00069661742172985235"}},"outputId":"27acdca6-2b4a-40e2-c229-0a0533d37863"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('ilm', 0.9665961265563965),\n"," ('films', 0.9600110650062561),\n"," ('filmed', 0.9400854706764221),\n"," ('filming', 0.8896265625953674),\n"," ('filmmaking', 0.8443182706832886),\n"," ('moviemaking', 0.8414859175682068),\n"," ('file', 0.8361199498176575),\n"," ('filmmaker', 0.8339509963989258),\n"," ('movie', 0.8196320533752441),\n"," ('filthy', 0.7854481339454651)]"]},"metadata":{},"execution_count":19}],"source":["# Your codes for Q3 c)\n","w2v_sg.wv.most_similar(positive=\"film\")\n","w2v_cbow.wv.most_similar(positive=\"film\")\n","ft_sg.wv.most_similar(positive=\"film\")\n","ft_cbow.wv.most_similar(positive=\"film\")"]},{"cell_type":"markdown","metadata":{"id":"JeQyWDTGBlr-"},"source":["**Answer: **\n","I used common words \"Film\" to find contextual words.\n","w2v_sg: reshoot, cerebral, artistically, inexcusable, counterbalance, adjectives, deliverance, stimulate, mislead.<br>\n","Explanation: SG is focused on predicting context given a target word, so it's likely to associate closely related terms that appear in similar contexts as \"artistically\" in movie reviews. <br>\n","w2v_cbow: movie, consider, entertainment, thriller, matrix, list, masterpiece, entertaining, cinematic, product<br>\n","CBOW predicts a word based on context, so it captures common collocates of \"film.\" This list includes general synonyms and related industry terms.<br>\n","ft_sg: 'movie', 'films', 'filmed', 'moviegoer', 'duguay', 'hk', 'moviemaking',\n"," 'mainstream', ilm, caligula<br>\n"," FastText breaks down words into subwords, it recognizes derivational forms like \"film's\" and \"filmmaker,\" along with closely related terms. The presence of compound words like \"films\", \"filmed\" and \"movie\", \"moviegoer\", \"moviemaking\" shows its sensitivity to subword cues.<br>\n"," ft_cbow: 'ilm', 'films', 'filmed', 'filming', 'filmmaking', 'moviemaking', 'file', 'filmmaker', 'movie', 'filthy'<br>\n"," ft_cbow captured a lot of subwords. <br>\n"," I would say ft_sg has the best performance, which is grealy related to the word film\n"]},{"cell_type":"markdown","metadata":{"id":"wAlo4bMt9SZi"},"source":["## Q4. Model Comparison with Pre-trained Embeddings\n","`gensim` also provides word embeddings pre-trained on some large corpus using different models. Next, we download some of these embeddings and compare them with our models to see the difference.\n","\n","### a) Downloading Pre-trained Embeddings\n","The embeddings that we choose are called `word2vec-google-news-300`. They are generated by the Word2Vec pre-trained on a part of the Google News dataset with about 100 billion words.\n","\n","You can run the following codes without any edits to download the embeddings. It may take around 10 mins."]},{"cell_type":"code","source":[],"metadata":{"id":"sg7U5Z3DSL0O"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NdMBNfv0kI3G","outputId":"0bf20ef7-c179-4081-d8ae-8907bd539c5e","executionInfo":{"status":"ok","timestamp":1719804872771,"user_tz":240,"elapsed":730647,"user":{"displayName":"Qi Tan","userId":"00069661742172985235"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"]}],"source":["import gensim.downloader\n","trained_w2c = gensim.downloader.load('word2vec-google-news-300')"]},{"cell_type":"markdown","metadata":{"id":"SE8DC6Ukk-xq"},"source":["### b) Comparison with Our Models\n","Next, we will compare our models with these pre-trained word embeddings.\n","\n","The following code generates the top-10 most similar words for \"**disney**\" using the pre-trained word embeddings. If the model is donwloaded correctly, the word \"disneyland\" and \"orlando\" should appear."]},{"cell_type":"code","execution_count":21,"metadata":{"id":"X-zm7Ofq-Z8a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719805822163,"user_tz":240,"elapsed":9069,"user":{"displayName":"Qi Tan","userId":"00069661742172985235"}},"outputId":"598cfd25-6054-4444-ca8a-1ec69992808a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('alice', 0.6571455597877502),\n"," ('harry_potter', 0.6108603477478027),\n"," ('gwen', 0.598574161529541),\n"," ('mario', 0.5946714878082275),\n"," ('nolan', 0.5925750732421875),\n"," ('disneyland', 0.584934413433075),\n"," ('orlando', 0.584503173828125),\n"," ('hannah_montana', 0.5791226029396057),\n"," ('jackie', 0.5755028128623962),\n"," ('nikki', 0.5743952989578247)]"]},"metadata":{},"execution_count":21}],"source":["trained_w2c.most_similar(positive=\"disney\")"]},{"cell_type":"markdown","metadata":{"id":"hY6mah-S-0wJ"},"source":["If you compare the above 10 words with the results in Q3 a), where our w2v_sg also generates the top-10 similar words of \"disney\", you may realize that although our models are trained on a much smaller dataset (around 12800:1 in terms of the number of tokens), they can also (even better) capture the word similarities in the context of movies. This illustrates the importance of domain-specific knowledge in language models.\n","\n","However, do our models alwasy perform well? Next, try to find the top-10 similar words of \"**computer**\" using both the pre-trained word embeddings `trained_w2c` and any one of our models. Compare the results and discuss why they generate such different results."]},{"cell_type":"code","execution_count":22,"metadata":{"id":"XxF3_H7wpY4I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719806009020,"user_tz":240,"elapsed":561,"user":{"displayName":"Qi Tan","userId":"00069661742172985235"}},"outputId":"c071b010-d25c-487a-d311-fe93884d9349"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('computers', 0.7979379892349243),\n"," ('laptop', 0.6640493273735046),\n"," ('laptop_computer', 0.6548868417739868),\n"," ('Computer', 0.647333562374115),\n"," ('com_puter', 0.6082080006599426),\n"," ('technician_Leonard_Luchko', 0.5662748217582703),\n"," ('mainframes_minicomputers', 0.5617720484733582),\n"," ('laptop_computers', 0.5585449934005737),\n"," ('PC', 0.5539618730545044),\n"," ('maker_Dell_DELL.O', 0.5519254207611084)]"]},"metadata":{},"execution_count":22}],"source":["# Your codes for Q4 b)\n","trained_w2c.most_similar(positive=\"computer\")"]},{"cell_type":"code","source":["w2v_sg.wv.most_similar(positive=\"computer\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0gf8m5_UUkRU","executionInfo":{"status":"ok","timestamp":1719806022777,"user_tz":240,"elapsed":142,"user":{"displayName":"Qi Tan","userId":"00069661742172985235"}},"outputId":"60175a0e-e586-45da-afbe-82d8b4b52296"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('plug', 0.7988744974136353),\n"," ('panama', 0.7644680738449097),\n"," ('aircraft', 0.7613723874092102),\n"," ('immerse', 0.7590673565864563),\n"," ('electrical', 0.7573085427284241),\n"," ('slime', 0.7563731074333191),\n"," ('exposure', 0.7525171041488647),\n"," ('detonate', 0.752166748046875),\n"," ('advanced', 0.7460222244262695),\n"," ('destroys', 0.7444332242012024)]"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"niTZjpK-phA2"},"source":["**Answer**: The trained_w2c has a much better result (laptop, PC, technician) compared to w2v_sg (plug, aircraft, exposure) that I used above. The reason being w2v_sg doens't have domain-specific knowledge in \"computer\" in movie reviews.\n"]},{"cell_type":"markdown","metadata":{"id":"wyQ1f3yIBlr_"},"source":["### c) Your Own Token\n","Come up with a word on your own, then generate the top-10 similar words under the pre-trained `trained_w2c` model and compare it with the top-10 similar words under the `ft_sg` we trained in Q3. Examine the output and discuss anything you find interesting."]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F9UTBe5kBlr_","executionInfo":{"status":"ok","timestamp":1719806163625,"user_tz":240,"elapsed":784,"user":{"displayName":"Qi Tan","userId":"00069661742172985235"}},"outputId":"3a8731dd-f82b-48d1-e11a-32ec3d04bacc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Steven_Spielberg_Artificial_Intelligence', 0.5575934052467346),\n"," ('Index_MDE_##/###/####', 0.5415324568748474),\n"," ('Enemy_AI', 0.5256390571594238),\n"," ('Ace_Combat_Zero', 0.522663414478302),\n"," ('DOA4', 0.5182536244392395),\n"," ('mechs', 0.5137375593185425),\n"," ('mech', 0.5077533721923828),\n"," ('playstyle', 0.507252037525177),\n"," ('AI_bots', 0.5051203370094299),\n"," ('deathmatch_mode', 0.5045916438102722)]"]},"metadata":{},"execution_count":24}],"source":["# Your codes for Q4 c)\n","trained_w2c.most_similar(positive=\"AI\")"]},{"cell_type":"code","source":["ft_sg.wv.most_similar(positive=\"AI\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Djxi5c_cEEM","executionInfo":{"status":"ok","timestamp":1719806223587,"user_tz":240,"elapsed":143,"user":{"displayName":"Qi Tan","userId":"00069661742172985235"}},"outputId":"635da123-e44f-4273-bbaf-e59a805bfe3c"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('pego', 0.8042883276939392),\n"," ('niccol', 0.7451541423797607),\n"," ('egoyan', 0.7275657057762146),\n"," ('screenwriting', 0.7199376225471497),\n"," ('akiva', 0.7163833379745483),\n"," ('irvin', 0.7145070433616638),\n"," ('koontz', 0.7029660940170288),\n"," ('crichton', 0.7007303237915039),\n"," ('irving', 0.6890618801116943),\n"," ('adapt', 0.6870779395103455)]"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"CLxgIxXOBlr_"},"source":["**Answer**: Again, The trained_w2c has a much better result (Steven_Spielberg_Artificial_Intelligence, Enemy_AI, AI_bots) compared to ft_sg (pego, niccol, egoyan) that I used above. The reason being ft_sg doens't have domain-specific knowledge in \"AI\" in movie reviews."]},{"cell_type":"markdown","metadata":{"id":"eYeytC-rpwkh"},"source":["When you finish Q4, delete the pre-trained word embeddings by running the following code to free up RAM.\n"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"CqcfBJNzp5wG","executionInfo":{"status":"ok","timestamp":1719806331012,"user_tz":240,"elapsed":131,"user":{"displayName":"Qi Tan","userId":"00069661742172985235"}}},"outputs":[],"source":["del trained_w2c"]},{"cell_type":"markdown","metadata":{"id":"h20Hlmh9AbZT"},"source":["---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"1MWeupge3A02"},"source":["## Q5 Non-Coding Questions:\n","\n","### a) Word Embeddings (for Word2Vec):\n","1. What does the word embedding vector tell us?\n"]},{"cell_type":"markdown","metadata":{"id":"jwqMBt_U3L-S"},"source":["A word embedding vector tells us<br><br>\n","\n","1.   Similarity Amoung words using cosine similarity. For example, doctor and hospital would be close.\n","2.   SG learns embeddings by predicting surrounding words in a sentence given a target word, capturing the contextual usage of words. CBOW predict a target word from its surrounding context, focusing more on how words tend to co-occur.\n","3.   Word embeddings can solve word analogies by simple vector arithmetic.\n","4.   FastText, include sub-word information which allows them to capture morphological relationships between words, such as tense, plurality, and other grammatical variations.\n","5.   Embeddings can capture broader language patterns and features. For example, they can reflect gender, tense, and other syntactic distinctions implicitly because these features affect how words are used in context."]},{"cell_type":"markdown","metadata":{"id":"IUZurzmw3Pho"},"source":["\n","2. What can I do if I care about the embeddings for a sentence as opposed to a word?\n"]},{"cell_type":"markdown","metadata":{"id":"f2D8Ot863VBU"},"source":["We can utilize\n","\n","\n","1.   non-weighted word embeddings\n","2.   weigthed averaging, like TF-IDF, put on different weights for better analysis\n","3.   RNN, recurrent neural networks or CNN, Convoluntional Neural Networds embeddings.\n","4.   Transformer-based models: BERT, GPT. BERT processes the entire sentence at once and generates a contextual embedding for each word.\n","5.   The Universal Sentence Encoder (USE). Transformer architecture or Deep averaging network.\n"]},{"cell_type":"markdown","metadata":{"id":"MoFkLf4M3WbN"},"source":["3. What happens if the word or token is not in the dictionary?\n","\n"]},{"cell_type":"markdown","metadata":{"id":"F2LQxIdl3ZUm"},"source":["w2v_sg will throw an error, where ft_sg will get similar list <br>\n","The unknown word can either be ignored, or marked as unknown, or tokenized to subwords(fasttext), or find its meaning from contextual embeddings."]},{"cell_type":"markdown","metadata":{"id":"lInHauIs3aSt"},"source":["### b) What is the difference between 'cbow' and 'skip-gram'? Does this explain the difference between results from\n","\n","```python\n","w2v_cbow.wv.most_similar(positive=\"disney\")\n","```\n","\n","and\n","\n","```python\n","w2v_sg.wv.most_similar(positive=\"disney\")\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qkXTaLCO3dJx"},"source":["**Answer:**\n","CBOW results: animate, dvd, decade, cinema, remake, version, animated, entry, theatrical, classic <br>\n","SG results: animation, animate, dreamworks, animated, pocahontas, mermaid, hercules, hunchback, walt, dame<br>\n","CBOW predicts a target word based on its context. Essentially, the model looks at a window of surrounding words (the context) and tries to predict the word in the middle of this window. It is usually faster than sg, and requires less data. However, it tends to oversimplify the context. <br>\n","SG predicts the context words from a target word. For each word in the corpus, it uses the current word as input and tries to predict words within a certain range before and after the current word. While slower, Skip-Gram tends to handle infrequent words better and can produce more detailed embeddings for a wider range of words.<br>\n","In our case, we can see cbow returned more variety of words, where sg returned words with different formats, for example, we are seeing animation, animate, animated, etc. It did capture pocahontas, hunchback which are rare words compared to cbow,"]},{"cell_type":"code","source":["w2v_cbow.wv.most_similar(positive=\"disney\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JvjDhKfTdq8c","executionInfo":{"status":"ok","timestamp":1719806639180,"user_tz":240,"elapsed":145,"user":{"displayName":"Qi Tan","userId":"00069661742172985235"}},"outputId":"020d0b4d-773f-43f9-c828-a19dd7c4d203"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('animate', 0.8779931664466858),\n"," ('dvd', 0.8596371412277222),\n"," ('decade', 0.8538360595703125),\n"," ('cinema', 0.8518430590629578),\n"," ('remake', 0.8399472832679749),\n"," ('version', 0.8386768102645874),\n"," ('animated', 0.8268529176712036),\n"," ('entry', 0.8246707916259766),\n"," ('theatrical', 0.8244009017944336),\n"," ('classic', 0.8214408755302429)]"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["w2v_sg.wv.most_similar(positive=\"disney\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l2aMbK6iduIw","executionInfo":{"status":"ok","timestamp":1719806651245,"user_tz":240,"elapsed":134,"user":{"displayName":"Qi Tan","userId":"00069661742172985235"}},"outputId":"fcb125e1-6706-4f0a-b803-ce8a3efab261"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('animation', 0.7560753226280212),\n"," ('animate', 0.7494263052940369),\n"," ('dreamworks', 0.7273356318473816),\n"," ('animated', 0.7238619923591614),\n"," ('pocahontas', 0.722666323184967),\n"," ('mermaid', 0.7204435467720032),\n"," ('hercules', 0.6872342824935913),\n"," ('hunchback', 0.6869755983352661),\n"," ('walt', 0.6835805177688599),\n"," ('dame', 0.6810756325721741)]"]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"34gRO2oA32Rk"},"source":["\n","\n","---\n","\n","## End of Assignment"]}],"metadata":{"colab":{"provenance":[{"file_id":"1ejOViw3SpXgUFwdvV4wBAyIyr-lfuyVr","timestamp":1719807261239}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}